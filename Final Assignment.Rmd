---
title: "Final Assignment"
author: "Isha Doshi"
date: "2022-12-12"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## 1.1 Explore life expectancy 

**1. Explain what is life expectancy. Here we talk about period life expectancy at birth, not cohort life expectancy.**

Answer:Life expectancy is a statistical measure of the average time someone is expected to live, based on the year of their birth, current age and other demographic factors including their sex. Period life expectancy assumes mortality rates remain constant into the future, while cohort life expectancy uses projected changes in future mortality rates. Period life expectancy (ex) is the average number of additional years a person would live if he or she experienced the age-specific mortality rates of the given area and time period for the rest of their life.
References:
1. https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/methodologies/guidetointerpretingpastandprojectedperiodandcohortlifetables#:~:text=Period%20and%20cohort%20life%20tables%20give%20two%20different%20measures%20of,changes%20in%20future%20mortality%20rates
2. https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/lifeexpectancies/methodologies/periodandcohortlifeexpectancyexplained

```{r}
library(dplyr)
library(tidyverse)
library(ggplot2)
```

**2. Load and clean the data–remove all cases with missing life expectancy, year and country name or code. You may have to return here later to improve cleaning if you discover more issues below. How many good cases do we have? Explain what steps you do, and in case the task is ambiguous, explain why you take exactly these steps too. Hint: data may have other problems than just NA values!**

```{r}
data=read.delim("gapminder.csv.bz2")
ncol(data)
nrow(data)
#renaming time to year
data=data %>%rename(year=time)
head(data)
#checking nulls
sum(is.na(data$lifeExpectancy))
sum(is.na(data$year))
sum(is.na(data$name))
sum(is.na(data$iso3))
sum(is.na(data$iso2))
#removing nulls and blanks
data = data[!(is.na(data$lifeExpectancy) | data$lifeExpectancy==""), ]
data = data[!(is.na(data$year) | data$year==""), ]
data = data[!(data$name==""), ]
data = data[!(data$iso3==""), ]
data = data[!(data$iso2==""), ]
ncol(data)
nrow(data)

```

**3. Now it is time to do some brief exploration:**

**(a) How many countries do we have in these data?**

Answer: There are 203 unique countries.
```{r}
length(unique(data$name))
```
**(b) What is the first and last year with valid life expectancy data?**

```{r}
first = min(data$year)
firstRow=data[which.min(data$year),]
firstRow
last = max(data$year)
lastRow=data[which.max(data$year),]
lastRow
cat("first year with valid life expectancy", first,"\n")
cat("last year with valid life expectancy ", last,"\n")
```
**(c) What is the lowest and highest life expectancy values? Which country/year do they correspond to?**

Answer:The lowest life expectancy wass present in Cambodia (1977)
The highest life expectancy was present in San Marino (2012)
Reference:https://stackoverflow.com/questions/19449615/how-to-extract-the-row-with-min-or-max-values
```{r}

min=data[which.min(data$lifeExpectancy),]
min
max=data[which.max(data$lifeExpectancy),]
max

```

**(d) If you did this correctly, you see that the shortest life expectancy corresponds to a well-known event. What is the event? (You may consult wikipedia if you do not know).**

Answer: The shortest life expectancy corresponds to a genocide in Cambodia which resulted in the death of 1.5 to 2 million people during 1975 to 1979

**4. Next, lets plot the life expectancy over time for all countries.**

Answer: I added Rwanda because there was a genocide in 1994 which resulted in deaths of 800,000 people.
```{r}
p <- ggplot(data=data, aes(x=year, y=lifeExpectancy, group=name, fill="gray")) +
    geom_line(alpha=0.1)
data_subset=data%>%filter(name=="United States of America"|name=="Korea, Republic of"|name=="Cambodia"|name=="China"|name=="Rwanda")
head(data_subset)
p=p+geom_line(data=data_subset, aes(x=year, y=lifeExpectancy,group=name, color=name, alpha=0.5))
p
```
**5. Explain what do you see on the graph. What is the overall picture? How do the selected countries behave? Anything else interesting you see?**

Answer: Life expectancy seems to be increasing over the years, probably due to better better health care and hygiene, healthier lifestyles, diet, and improved medical care. China's life expectancy improved greatly during the 70s. United States and Korea too has had a better life expectancy over the years. There are dips in Cambodia and Rwanda's life expectancy due to genocide and tragic killings in the country. 

**6. Now, let’s look at how are life expectancy and fertility related. Make a fertility rate versus life expectancy plot of all countries with selected countries highlighted. Use arrows to mark which way the time goes on the figure.**

```{r}
plot <- ggplot(data=data, aes(x=lifeExpectancy, y=fertilityRate, group=name, fill="gray")) +
    geom_line(alpha=0.1,arrow = arrow())
plot=plot+geom_line(data=data_subset, aes(x=lifeExpectancy, y=fertilityRate, group=name, color=name),arrow = arrow(length=unit(0.10,"cm")))
plot
```

**7. Comment the results. Where is the world going? Where are the highlighted countries going?**

Answer: Fertility rate is decreasing while life expectancy is increasing over time. The reason why fertility rate could be decreasing might be because of women empowerment in education and the workforce, lower child mortality and the increased cost of raising children. The highlighted countries are also following the same trend.
 
Reference: https://www.weforum.org/agenda/2022/06/global-decline-of-fertility-rates-visualised/

## 1.2 Model life expectancy (40pt)
**1. Display the distribution of life expectancy. How does it look like? Does it suggest you should use log-transformation? Explain!**

Answer: It is a little left skewed. We can try log-transformation to see if it distributes the data more normally. Log transformation is making it more left skewed, it would be better to not perform log transformation in this case.
```{r}
library(ggplot2)
ggplot(data, aes(x=lifeExpectancy)) +
    geom_histogram(binwidth=4)

library(ggplot2)
ggplot(data, aes(x=log(lifeExpectancy))) +
    geom_histogram(bins=30)
```
**2. Create a model where you explain life expectancy with just time, where t is time (year). Use year − 2000 instead of just year for time.**

```{r}
data$mod_year=data$year-2000
head(data)
model<-lm(lifeExpectancy~mod_year,data=data)
summary(model)
```

**3. Why does year − 2000 make more sense?**

Answer: Since the data has data points far from each other, scaling technique will help make them closer to each other or in simpler words, scaling will make the data points generalized so that the distance between them will be lower. If the difference between the data points is very high, the model could be unstable, which would result in the model producing poor results. Another reason why this makes more sense is the intercept comes as negative without changing the year, and since life expectancy cannot be negative, it makes sense to scale the data.

Reference:https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/#:~:text=So%20if%20the%20data%20in,between%20them%20will%20be%20lower.

**4. Interpret the results (both β0 and β1).**

Answer: b0 here is 67.40, which is the life expectancy when the year is 0, and b1 is 0.30 which is the coefficient of how year parameter affects the life expectancy.

**5. Now let’s move to multiple regression: estimate the model where you also add the continent (variable region)**

```{r}
model1<-lm(lifeExpectancy~mod_year+region,data=data)
summary(model1)
```
**6. Interpret the results. What do the region dummies mean? What is the reference category? How big is the time trend? Is it statistically significant? Is it different from what you saw in the previous model?**

Answer: The region dummies are Americas, Asia, Europe and Oceania. The reference category is Africas. The p value for time trend is <2e-16. The time trend is statistically significant as the probability is less than 0.05. This model performs better than the previous one, since the r square value is higher here. 

**7. As a final result, let’s add two additional variables to the model: log of GDP per capita, and fertility rate. Estimate such a model.**

Answer: This model performs better as the adjusted R square is 0.8485, which is higher the the previous two models.
```{r}
model2<-lm(lifeExpectancy~mod_year+region+fertilityRate+log(GDP_PC),data=data)
summary(model2)
```

**8. What do the estimated parameters (betas) for the two new variables tell you?**

Answer: All betas are statistically significant. Fertility rate intercept is now negative. The region dummy values have changed a bit. Europe was the leading region in Question 5, but now Americas is leading the pack in terms of the value.

**9. If you did it correctly, you noticed that Europe was the leading region in Question 5. But now Americas is leading the pack in terms of the value of the region dummy–the dummy for Europe is only 4th largest. Explain why adding additional variables made the ranking of continents to look different.**

Answer: Yes, there is a difference in which region is leading based on value of region dummy. Additional variables made the ranking of the continents look different as each additional variable brings new beta which alters how the parameters are interacting with the dependent variable.

**10. Based on all the models you have done so far: which continent has the highest life expectancy? Which one the lowest?**

Answer: Based on the most recent model, Americas has the highest life expectancy followed by Asia then Oceania then Europe. We come to this conclusion from the beta values.

## 2 Find Cheap Restaurants

**1. Load the data and perform basic sanity checks. Ensure you know the variables. Check for missings and unreasonable values and clean the data as necessary.**
```{r}
restaurant=read.delim("nyc-italian-cheap.csv.bz2")
head(restaurant)
sum(is.na(restaurant))
summary(restaurant)
```
**2. Your task is to predict if a restaurant is cheap or not. Which type of model, linear or logistic regression do you think is suitable for this task? Explain!**

Answer: Logistic regression would be suitable for this task, as logistic regression is the best for questions with binary responses. Here the restaurant can be either cheap (1) or not(0). Hence that would be the most suitable.

**3. Now build the model. Include all the variables you consider relevant for this task. Estimate the model and interpret the statistically significant results. Do your results align with common sense? Ensure you interpret the right type of effects.**

Answer: Food and decor are statistically significant whereas service and east are not (p value less than 0.05 is statistically significant). The AIC value is 149.7. Yes, the results align with common sense, expensive restaurants should have better decor and food. The model doesn't improve much after removing service and east though. The AIC score becomes 146.31. 

```{r}
model3=glm(data=restaurant, Cheap~Food+Decor+Service+East, family=binomial())
summary(model3)

model4=glm(data=restaurant, Cheap~Food+Decor, family=binomial())
summary(model4)
```

**4. You are going out with a few friends and feeling hungry, and would like to have lunch at a not-too-expensive Italian place. You find there are two new places with the following scores and locations:**

Answer: The restaurant Altura is a cheap Italian place where I could go with a few friends. 
```{r}
Restaurant <- c("Assagio Ristorante", "Altura")
Food <- c(23, 18)
Decor <- c(17, 15)
Service <-c(22,24)
Eastside <-c(0,1)
test_df <- data.frame(Restaurant,Food,Decor,Service,Eastside)
test_df

CheapValue = predict(model4, test_df)
test_df=test_df%>%mutate(Cheap=case_when(CheapValue>=1~1,CheapValue<0~0))
test_df
```
## 3 Theoretical questions (20pt)

**1. Describe one real-life applications in which logistic regression may be useful, one in which linear regression is useful, and one in which prediction is useful. Describe the response, as well as the predictors. Explain your answer.**

Answer: One real life application for logistic regression would be to determine if a student will get an internship or not. Some of the predictors to determine that could be gpa, previous industry work experience, and skills. One real life application of linear regression could be predicting the yearly income of a person. The predictors could be total years of schooling and weekly hours worked. Prediction would be useful when we predict a value based on the population we sampled. 

References: https://www.statology.org/predictions-regression/#:~:text=Example%201%3A%20Make%20Predictions%20with,What%20is%20this%3F&text=She%20then%20fits%20a%20simple,height%E2%80%9D%20as%20the%20response%20variable.  

**2. Think about analyzing regression results. What does this mean: A coefficient is statistically significant at 5% confidence level?**

Answer: The confidence level is equivalent to 1 – the alpha level. So, if our significance level is 0.05, the corresponding confidence level is 95%.

If the P value is less than our significance (alpha) level, the hypothesis test is statistically significant.
If the confidence interval does not contain the null hypothesis value, the results are statistically significant.
If the P value is less than alpha, the confidence interval will not contain the null hypothesis value.

**3. You are network security manager. Your network has recently suffered from various attacks and intrusions and now you are evaluating to introduce a new login method, either method L1 or method L2. The login will distinguish between approved users (A) and intruders (I) based on passwords, biometrics and other data. The small-scale evaluation you did produced the following results:**

**(a) Show the confusion matrices for methods L1 and L2. Do it as markdown tables.**

Answer: Taking I as positive (1) and A as negative (0), let's add the data to a dataframe and then into a table. 

```{r}

Actual <- c(0,1,1,0,0,1,1,1,1,1)
RegisteredL1 <- c(0,0,1,0,0,1,0,1,0,1)
RegisteredL2<-c(0,1,1,1,0,1,1,1,1,1)
Attacks_df <- data.frame(Actual,RegisteredL1,RegisteredL2)
Attacks_df

table(Attacks_df$RegisteredL1, Attacks_df$Actual)
table(Attacks_df$RegisteredL2, Attacks_df$Actual)
```

**(b) Compute accuracy, precision, recall for both models. To stay on the same page, let’s take “I” as positive.**

```{r}
AccuracyL1=(3+4)/(3+4+3+0)
PrecisionL1=4/(4+0)
RecallL1=4/(3+4)
AccuracyL2=(7+2)/(1+2+7+0)
PrecisionL2=7/(7+1)
RecallL2=7/(0+7)
AccuracyL1
PrecisionL1
RecallL1
AccuracyL2
PrecisionL2
RecallL2
```
**(c) Which login method, L1 or L2 will you recommend the management to implement? Explain your reasoning. Note: you can argue in different ways depending on what do you think about security and access needs. It is not important what do you assume but it is important you explain your reasoning!**

Answer: Using F-Measure = (2 * Precision * Recall) / (Precision + Recall), we can decide which login method is better. F-Measure gives a better measure of the incorrectly classified cases than the Accuracy Metric. Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial. Here False Negatives and False Positives are crucial hence F-Measure makes more sense.Since L2 has a better F-Measure, I would recommend L2 to the management.

Reference:https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2
```{r}
FL1= (2*PrecisionL1*RecallL1)/(PrecisionL1+RecallL1)
FL2= (2*PrecisionL2*RecallL2)/(PrecisionL2+RecallL2)
FL1
FL2
```
I affirm that I have had no conversation regarding this exam with any persons other than the instructor and/or the teaching assistant. Further, I certify that the attached work represents my own thinking. Any information, concepts, or words that originate from other sources are cited in accordance with University of Washington guidelines as published in the Academic Code (available on the course website). I am aware of the serious consequences that result from improper discussions with others or from the improper citation of work that is not my own.


Isha Doshi


12th Dec 2022